{
  "direct_llm": {
    "diagnosis": {
      "n_scored": 80,
      "accuracy": 0.75,
      "n_correct": 60,
      "rouge_l": 0.10432989959695556,
      "token_f1": 0.13010667454862002,
      "term_level": {
        "tp": 83,
        "fp": 383,
        "fn": 232,
        "precision": 0.1781115879828326,
        "recall": 0.2634920634920635,
        "f1": 0.21254801536491677,
        "tier_breakdown": {
          "no_match": 383,
          "ita_match": 18,
          "word_overlap": 56,
          "fuzzy_match": 9
        }
      }
    },
    "treatment": {
      "n_scored": 80,
      "accuracy": 1.0,
      "n_correct": 80,
      "rouge_l": 0.0336334129180942,
      "token_f1": 0.08270282940588859,
      "term_level": {
        "tp": 386,
        "fp": 3812,
        "fn": 385,
        "precision": 0.09194854692710815,
        "recall": 0.5006485084306096,
        "f1": 0.15536325216341315,
        "tier_breakdown": {
          "no_match": 3812,
          "word_overlap": 386
        }
      }
    }
  },
  "full_pipeline": {
    "diagnosis": {
      "n_scored": 80,
      "accuracy": 0.8,
      "n_correct": 64,
      "rouge_l": 0.06452439374395749,
      "token_f1": 0.08780640104152251,
      "term_level": {
        "tp": 109,
        "fp": 1704,
        "fn": 206,
        "precision": 0.06012134583563155,
        "recall": 0.346031746031746,
        "f1": 0.10244360902255639,
        "tier_breakdown": {
          "word_overlap": 77,
          "no_match": 1704,
          "fuzzy_match": 8,
          "ita_match": 24
        }
      }
    },
    "treatment": {
      "n_scored": 80,
      "accuracy": 1.0,
      "n_correct": 80,
      "rouge_l": 0.060256220958774906,
      "token_f1": 0.1251453903403526,
      "term_level": {
        "tp": 351,
        "fp": 2079,
        "fn": 420,
        "precision": 0.14444444444444443,
        "recall": 0.45525291828793774,
        "f1": 0.2193064667291471,
        "tier_breakdown": {
          "no_match": 2079,
          "word_overlap": 348,
          "fuzzy_match": 3
        }
      }
    }
  },
  "bridge_only": {
    "diagnosis": {
      "n_scored": 80,
      "accuracy": 0.05,
      "n_correct": 4,
      "rouge_l": 0.003125,
      "token_f1": 0.003125,
      "term_level": {
        "tp": 4,
        "fp": 178,
        "fn": 311,
        "precision": 0.02197802197802198,
        "recall": 0.012698412698412698,
        "f1": 0.01609657947686117,
        "tier_breakdown": {
          "no_match": 178,
          "ita_match": 4
        }
      }
    },
    "treatment": {
      "n_scored": 80,
      "accuracy": 0.0,
      "n_correct": 0,
      "rouge_l": 0.0,
      "token_f1": 0.0,
      "term_level": {
        "tp": 0,
        "fp": 0,
        "fn": 771,
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "tier_breakdown": {}
      }
    }
  }
}